{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# &#128640; Growth Equestre | Caminho #1 - Lead Scoring com Dois Modelos\n",
        "\n",
        "**Objetivo:** treinar **2 modelos candidatos** para propensao de qualificacao de leads, aplicar **GridSearchCV + fine tuning** e definir um **criterio profissional de desempate**.\n",
        "\n",
        "## &#127919; Entregaveis deste notebook\n",
        "- Modelo campeao (`best_model`)\n",
        "- Modelo vice (`runner_up_model`)\n",
        "- Relatorio de comparacao com metricas\n",
        "- Criterio de desempate documentado para auditoria\n",
        "- Artefatos exportados em `data/ml/artifacts/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## &#129517; Estrategia de Modelagem\n",
        "\n",
        "### Modelos candidatos\n",
        "1. **Regressao Logistica** (baseline explicavel)\n",
        "2. **Random Forest** (nao linear, robusto a interacoes)\n",
        "\n",
        "### Metrica principal\n",
        "- **ROC-AUC (validacao)**\n",
        "\n",
        "### Criterio de desempate\n",
        "Se a diferenca de ROC-AUC entre os 2 melhores for <= `0.005`, desempatar por:\n",
        "1. maior **PR-AUC**\n",
        "2. menor **Brier Score**\n",
        "3. menor **latencia de inferencia**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalando: scikit-learn, joblib, matplotlib, seaborn\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "pkg_map = {\n",
        "    \"pandas\": \"pandas\",\n",
        "    \"numpy\": \"numpy\",\n",
        "    \"sklearn\": \"scikit-learn\",   # módulo -> pacote pip correto\n",
        "    \"joblib\": \"joblib\",\n",
        "    \"matplotlib\": \"matplotlib\",\n",
        "    \"seaborn\": \"seaborn\",\n",
        "    \"jinja2\": \"jinja2\",\n",
        "}\n",
        "\n",
        "missing = [pip_name for mod_name, pip_name in pkg_map.items()\n",
        "           if importlib.util.find_spec(mod_name) is None]\n",
        "\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
        "\n",
        "if missing:\n",
        "    print(\"Instalando:\", \", \".join(missing))\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
        "\n",
        "print(\"OK\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## &#128451;&#65039; Extracao do Dataset (Postgres -> CSV)\n",
        "\n",
        "Esta celula gera um dataset tabular para treino com features de perfil + eventos do funil.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "mkdir -p data/ml\n",
        "\n",
        "QUERY=$(cat <<'SQL'\n",
        "\\copy (\n",
        "  WITH event_agg AS (\n",
        "    SELECT\n",
        "      lead_id,\n",
        "      COUNT(*)::int AS n_events,\n",
        "      COUNT(*) FILTER (WHERE event_type = 'page_view')::int AS n_page_view,\n",
        "      COUNT(*) FILTER (WHERE event_type = 'hook_complete')::int AS n_hook_complete,\n",
        "      COUNT(*) FILTER (WHERE event_type IN ('cta_click', 'whatsapp_click'))::int AS n_cta_click,\n",
        "      EXTRACT(EPOCH FROM (now() - MAX(ts))) / 3600.0 AS recency_last_event_hours\n",
        "    FROM events\n",
        "    GROUP BY lead_id\n",
        "  )\n",
        "  SELECT\n",
        "    l.id AS lead_id,\n",
        "    COALESCE(l.uf, '') AS uf,\n",
        "    COALESCE(l.cidade, '') AS cidade,\n",
        "    COALESCE(l.segmento_interesse, '') AS segmento_interesse,\n",
        "    COALESCE(l.orcamento_faixa, '') AS orcamento_faixa,\n",
        "    COALESCE(l.prazo_compra, '') AS prazo_compra,\n",
        "    COALESCE(l.status, 'CURIOSO') AS status,\n",
        "    COALESCE(e.n_events, 0) AS n_events,\n",
        "    COALESCE(e.n_page_view, 0) AS n_page_view,\n",
        "    COALESCE(e.n_hook_complete, 0) AS n_hook_complete,\n",
        "    COALESCE(e.n_cta_click, 0) AS n_cta_click,\n",
        "    COALESCE(e.recency_last_event_hours, 9999) AS recency_last_event_hours,\n",
        "    CASE\n",
        "      WHEN UPPER(COALESCE(l.status, '')) IN ('QUALIFICADO', 'ENVIADO') THEN 1\n",
        "      ELSE 0\n",
        "    END AS label_qualified\n",
        "  FROM leads l\n",
        "  LEFT JOIN event_agg e ON e.lead_id = l.id\n",
        ") TO STDOUT WITH CSV HEADER\n",
        "SQL\n",
        ")\n",
        "\n",
        "docker compose exec -T db psql -U app -d appdb -c \"$QUERY\" > data/ml/lead_scoring_dataset.csv\n",
        "\n",
        "echo \"Dataset gerado em: data/ml/lead_scoring_dataset.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8471389c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bibliotecas padrao para IO e controle do fluxo de treino.\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Persistencia de modelos e manipulacao tabular.\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Blocos principais do ecossistema sklearn para pipeline e avaliacao.\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    brier_score_loss,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Configuracoes globais para reproducibilidade e padrao de artefatos.\n",
        "RANDOM_STATE = 42\n",
        "TARGET_COL = \"label_qualified\"\n",
        "DATA_PATH = Path(\"data/ml/lead_scoring_dataset.csv\")\n",
        "ARTIFACT_DIR = Path(\"data/ml/artifacts\")\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Facilita debug visual no notebook.\n",
        "pd.set_option(\"display.max_columns\", 200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b9c8225f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linhas totais: 458 (removidas 0 sem target)\n",
            "Distribuicao de classe:\n",
            "label_qualified\n",
            "0    0.8013\n",
            "1    0.1987\n",
            "Name: ratio, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lead_id</th>\n",
              "      <th>uf</th>\n",
              "      <th>cidade</th>\n",
              "      <th>segmento_interesse</th>\n",
              "      <th>orcamento_faixa</th>\n",
              "      <th>prazo_compra</th>\n",
              "      <th>status</th>\n",
              "      <th>n_events</th>\n",
              "      <th>n_page_view</th>\n",
              "      <th>n_hook_complete</th>\n",
              "      <th>n_cta_click</th>\n",
              "      <th>recency_last_event_hours</th>\n",
              "      <th>label_qualified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a484c6af-f02a-4509-a2b1-53a7f1647db4</td>\n",
              "      <td>GO</td>\n",
              "      <td>Rio Verde</td>\n",
              "      <td>EQUIPAMENTOS</td>\n",
              "      <td>60k+</td>\n",
              "      <td>90d</td>\n",
              "      <td>CURIOSO</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1932.080053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80e25dfa-ffd0-4995-8d2f-4baf846035c5</td>\n",
              "      <td>SP</td>\n",
              "      <td>Sao Jose dos Campos</td>\n",
              "      <td>EQUIPAMENTOS</td>\n",
              "      <td>60k+</td>\n",
              "      <td>7d</td>\n",
              "      <td>ENVIADO</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>693.746719</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>447641a0-3e48-4e17-aa07-053b00bbfdbf</td>\n",
              "      <td>SP</td>\n",
              "      <td>Campinas</td>\n",
              "      <td>EVENTOS</td>\n",
              "      <td>20k-60k</td>\n",
              "      <td>90d</td>\n",
              "      <td>CURIOSO</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1806.696719</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                lead_id  uf               cidade  \\\n",
              "0  a484c6af-f02a-4509-a2b1-53a7f1647db4  GO            Rio Verde   \n",
              "1  80e25dfa-ffd0-4995-8d2f-4baf846035c5  SP  Sao Jose dos Campos   \n",
              "2  447641a0-3e48-4e17-aa07-053b00bbfdbf  SP             Campinas   \n",
              "\n",
              "  segmento_interesse orcamento_faixa prazo_compra   status  n_events  \\\n",
              "0       EQUIPAMENTOS            60k+          90d  CURIOSO         2   \n",
              "1       EQUIPAMENTOS            60k+           7d  ENVIADO         8   \n",
              "2            EVENTOS         20k-60k          90d  CURIOSO         1   \n",
              "\n",
              "   n_page_view  n_hook_complete  n_cta_click  recency_last_event_hours  \\\n",
              "0            1                1            0               1932.080053   \n",
              "1            5                1            2                693.746719   \n",
              "2            1                0            0               1806.696719   \n",
              "\n",
              "   label_qualified  \n",
              "0                0  \n",
              "1                1  \n",
              "2                0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1) Garantia de existencia do dataset.\n",
        "if not DATA_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Arquivo nao encontrado: {DATA_PATH}. Rode a celula de extracao SQL primeiro.\"\n",
        "    )\n",
        "\n",
        "# 2) Carrega o CSV de treino.\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# 3) Validacao de schema minimo esperado pelo pipeline.\n",
        "required_cols = {\n",
        "    \"uf\", \"cidade\", \"segmento_interesse\", \"orcamento_faixa\", \"prazo_compra\",\n",
        "    \"n_events\", \"n_page_view\", \"n_hook_complete\", \"n_cta_click\", \"recency_last_event_hours\",\n",
        "}\n",
        "missing = required_cols.difference(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Colunas obrigatorias ausentes no dataset: {sorted(missing)}\")\n",
        "\n",
        "# 4) Se a label nao vier pronta, deriva pelo status comercial final.\n",
        "if TARGET_COL not in df.columns:\n",
        "    if \"status\" not in df.columns:\n",
        "        raise ValueError(\"Dataset sem label_qualified e sem status para derivar o alvo.\")\n",
        "    df[TARGET_COL] = df[\"status\"].astype(str).str.upper().isin([\"QUALIFICADO\", \"ENVIADO\"]).astype(int)\n",
        "\n",
        "# 5) O treino supervisionado exige ao menos duas classes no alvo.\n",
        "if df[TARGET_COL].nunique() < 2:\n",
        "    raise ValueError(\n",
        "        \"Target com apenas uma classe. Gere mais dados de demo (QUALIFICADO/ENVIADO e CURIOSO/AQUECENDO).\"\n",
        "    )\n",
        "\n",
        "# 6) Coerce de colunas numericas para garantir compatibilidade no pipeline.\n",
        "for c in [\"n_events\", \"n_page_view\", \"n_hook_complete\", \"n_cta_click\", \"recency_last_event_hours\"]:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# 7) Limpeza final: remove linhas sem target.\n",
        "before = len(df)\n",
        "df = df.dropna(subset=[TARGET_COL]).copy()\n",
        "after = len(df)\n",
        "\n",
        "# 8) Diagnostico rapido do dataset apos limpeza.\n",
        "print(f\"Linhas totais: {after} (removidas {before - after} sem target)\")\n",
        "print(\"Distribuicao de classe:\")\n",
        "print(df[TARGET_COL].value_counts(normalize=True).rename(\"ratio\").round(4))\n",
        "\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e09b05",
      "metadata": {},
      "source": [
        "## &#129504; Preparacao de Features e Split\n",
        "\n",
        "- **Treino:** 70%\n",
        "- **Validacao:** 15%\n",
        "- **Teste:** 15%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3f23accf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes:\n",
            "  Train: (320, 10), Valid: (69, 10), Test: (69, 10)\n",
            "CV folds ajustado para: 5\n"
          ]
        }
      ],
      "source": [
        "# Definicao de grupos de features para facilitar manutencao.\n",
        "numeric_features = [\n",
        "    \"n_events\",\n",
        "    \"n_page_view\",\n",
        "    \"n_hook_complete\",\n",
        "    \"n_cta_click\",\n",
        "    \"recency_last_event_hours\",\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    \"uf\",\n",
        "    \"cidade\",\n",
        "    \"segmento_interesse\",\n",
        "    \"orcamento_faixa\",\n",
        "    \"prazo_compra\",\n",
        "]\n",
        "\n",
        "# Seleciona X e y no formato esperado pelo sklearn.\n",
        "feature_cols = numeric_features + categorical_features\n",
        "X = df[feature_cols].copy()\n",
        "y = df[TARGET_COL].astype(int)\n",
        "\n",
        "# Split 70/15/15 mantendo proporcao de classes (stratify).\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.30,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.50,\n",
        "    stratify=y_temp,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(f\"  Train: {X_train.shape}, Valid: {X_valid.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "# Ajuste dinamico dos folds para evitar erro em datasets pequenos.\n",
        "class_min_count = y_train.value_counts().min()\n",
        "cv_splits = max(2, min(5, int(class_min_count)))\n",
        "print(f\"CV folds ajustado para: {cv_splits}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b69afff6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline de preprocessamento para regressao logistica.\n",
        "# Inclui scaling para estabilizar coeficientes em features numericas.\n",
        "preprocess_logit = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\n",
        "            \"num\",\n",
        "            Pipeline(\n",
        "                steps=[\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                ]\n",
        "            ),\n",
        "            numeric_features,\n",
        "        ),\n",
        "        (\n",
        "            \"cat\",\n",
        "            Pipeline(\n",
        "                steps=[\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "                ]\n",
        "            ),\n",
        "            categorical_features,\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline de preprocessamento para Random Forest.\n",
        "# Nao precisa de scaling, mas mantem imputacao + one-hot.\n",
        "preprocess_rf = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\n",
        "            \"num\",\n",
        "            Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]),\n",
        "            numeric_features,\n",
        "        ),\n",
        "        (\n",
        "            \"cat\",\n",
        "            Pipeline(\n",
        "                steps=[\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "                ]\n",
        "            ),\n",
        "            categorical_features,\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Encadeia preprocessamento + estimador para busca de hiperparametros.\n",
        "pipe_logit = Pipeline(\n",
        "    steps=[\n",
        "        (\"prep\", preprocess_logit),\n",
        "        (\n",
        "            \"model\",\n",
        "            LogisticRegression(\n",
        "                max_iter=2500,\n",
        "                solver=\"liblinear\",\n",
        "                random_state=RANDOM_STATE,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipe_rf = Pipeline(\n",
        "    steps=[\n",
        "        (\"prep\", preprocess_rf),\n",
        "        (\n",
        "            \"model\",\n",
        "            RandomForestClassifier(\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_jobs=-1,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Grade base para a 1a rodada de GridSearchCV.\n",
        "param_grid_logit = {\n",
        "    \"model__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "    \"model__penalty\": [\"l1\", \"l2\"],\n",
        "    \"model__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    \"model__n_estimators\": [200, 400, 700],\n",
        "    \"model__max_depth\": [None, 8, 16],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "    \"model__min_samples_leaf\": [1, 2, 4],\n",
        "    \"model__class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
        "}\n",
        "\n",
        "# CV estratificado para comparacao justa entre combinacoes de hiperparametros.\n",
        "cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788d9d19",
      "metadata": {},
      "source": [
        "## &#128269; GridSearchCV (Treino Base)\n",
        "\n",
        "Executa busca de hiperparametros para os 2 modelos usando **ROC-AUC**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0d7e24bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Treinando LogisticRegression com GridSearchCV...\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
            "  warnings.warn(\n",
            "c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhor ROC-AUC CV (LogisticRegression): 0.9774\n",
            "Melhores params: {'model__C': 0.1, 'model__class_weight': None, 'model__penalty': 'l1'}\n",
            "\n",
            ">>> Treinando RandomForest com GridSearchCV...\n",
            "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
            "Melhor ROC-AUC CV (RandomForest): 0.9805\n",
            "Melhores params: {'model__class_weight': None, 'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "def run_grid_search(name, pipeline, param_grid, X_train, y_train):\n",
        "    # Wrapper para evitar repeticao e padronizar logging.\n",
        "    print(f\"\\n>>> Treinando {name} com GridSearchCV...\")\n",
        "    gs = GridSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"roc_auc\",  # metrica principal do projeto\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        refit=True,  # refit no melhor conjunto de hiperparametros\n",
        "    )\n",
        "    gs.fit(X_train, y_train)\n",
        "    print(f\"Melhor ROC-AUC CV ({name}): {gs.best_score_:.4f}\")\n",
        "    print(\"Melhores params:\", gs.best_params_)\n",
        "    return gs\n",
        "\n",
        "\n",
        "# Rodada base (busca ampla) para os dois candidatos.\n",
        "gs_logit = run_grid_search(\"LogisticRegression\", pipe_logit, param_grid_logit, X_train, y_train)\n",
        "gs_rf = run_grid_search(\"RandomForest\", pipe_rf, param_grid_rf, X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab834e4d",
      "metadata": {},
      "source": [
        "## &#127912; Fine Tuning (2a rodada)\n",
        "\n",
        "Refina o espaco de busca ao redor dos melhores parametros encontrados na rodada base.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7075dd6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Treinando LogisticRegression (fine) com GridSearchCV...\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Melhor ROC-AUC CV (LogisticRegression (fine)): 0.9774\n",
            "Melhores params: {'model__C': 0.05, 'model__class_weight': None, 'model__penalty': 'l1'}\n",
            "\n",
            ">>> Treinando RandomForest (fine) com GridSearchCV...\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
            "  warnings.warn(\n",
            "c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhor ROC-AUC CV (RandomForest (fine)): 0.9805\n",
            "Melhores params: {'model__class_weight': None, 'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "def build_fine_grid_logit(best_params):\n",
        "    # Refina C ao redor do melhor valor da rodada base.\n",
        "    c = float(best_params[\"model__C\"])\n",
        "    c_candidates = sorted({max(1e-4, round(v, 5)) for v in [c * 0.5, c * 0.75, c, c * 1.25, c * 1.5]})\n",
        "    return {\n",
        "        \"model__C\": c_candidates,\n",
        "        \"model__penalty\": [best_params[\"model__penalty\"]],\n",
        "        \"model__class_weight\": [best_params[\"model__class_weight\"], \"balanced\"],\n",
        "    }\n",
        "\n",
        "\n",
        "def build_fine_grid_rf(best_params):\n",
        "    # Refina floresta ao redor do melhor ponto base.\n",
        "    n_estimators = int(best_params[\"model__n_estimators\"])\n",
        "    max_depth = best_params[\"model__max_depth\"]\n",
        "    min_split = int(best_params[\"model__min_samples_split\"])\n",
        "    min_leaf = int(best_params[\"model__min_samples_leaf\"])\n",
        "\n",
        "    n_estimators_candidates = sorted({max(100, n_estimators - 150), n_estimators, n_estimators + 150})\n",
        "\n",
        "    depth_candidates = [max_depth]\n",
        "    if isinstance(max_depth, int):\n",
        "        depth_candidates = sorted({max(3, max_depth - 4), max_depth, max_depth + 4})\n",
        "\n",
        "    return {\n",
        "        \"model__n_estimators\": n_estimators_candidates,\n",
        "        \"model__max_depth\": depth_candidates,\n",
        "        \"model__min_samples_split\": sorted({max(2, min_split - 1), min_split, min_split + 1}),\n",
        "        \"model__min_samples_leaf\": sorted({max(1, min_leaf - 1), min_leaf, min_leaf + 1}),\n",
        "        \"model__class_weight\": [best_params[\"model__class_weight\"], \"balanced_subsample\"],\n",
        "    }\n",
        "\n",
        "\n",
        "# Grades refinadas da 2a rodada.\n",
        "fine_grid_logit = build_fine_grid_logit(gs_logit.best_params_)\n",
        "fine_grid_rf = build_fine_grid_rf(gs_rf.best_params_)\n",
        "\n",
        "# Rodada de fine tuning.\n",
        "fine_logit = run_grid_search(\"LogisticRegression (fine)\", pipe_logit, fine_grid_logit, X_train, y_train)\n",
        "fine_rf = run_grid_search(\"RandomForest (fine)\", pipe_rf, fine_grid_rf, X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbf3a23",
      "metadata": {},
      "source": [
        "## &#128202; Avaliacao e Criterio de Desempate\n",
        "\n",
        "Regra implementada:\n",
        "- 1o: maior **ROC-AUC validacao**\n",
        "- empate tecnico (<= 0.005): maior **PR-AUC validacao**\n",
        "- persistindo empate: menor **Brier validacao**\n",
        "- persistindo empate: menor **latencia (ms/registro)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e6c7f2b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>val_roc_auc</th>\n",
              "      <th>val_pr_auc</th>\n",
              "      <th>val_brier</th>\n",
              "      <th>val_f1</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_latency_ms</th>\n",
              "      <th>test_roc_auc</th>\n",
              "      <th>test_pr_auc</th>\n",
              "      <th>test_brier</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_latency_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logit_fine</td>\n",
              "      <td>0.967532</td>\n",
              "      <td>0.818432</td>\n",
              "      <td>0.069498</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.059996</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.038144</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.057081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rf_fine</td>\n",
              "      <td>0.959740</td>\n",
              "      <td>0.844241</td>\n",
              "      <td>0.073611</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.430552</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.016229</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.426639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        model  val_roc_auc  val_pr_auc  val_brier    val_f1  val_precision  \\\n",
              "0  logit_fine     0.967532    0.818432   0.069498  0.695652       0.888889   \n",
              "1     rf_fine     0.959740    0.844241   0.073611  0.695652       0.888889   \n",
              "\n",
              "   val_recall  val_latency_ms  test_roc_auc  test_pr_auc  test_brier  test_f1  \\\n",
              "0    0.571429        0.059996           1.0          1.0    0.038144      1.0   \n",
              "1    0.571429        0.430552           1.0          1.0    0.016229      1.0   \n",
              "\n",
              "   test_precision  test_recall  test_latency_ms  \n",
              "0             1.0          1.0         0.057081  \n",
              "1             1.0          1.0         0.426639  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate_estimator(name, estimator, X_valid, y_valid, X_test, y_test):\n",
        "    # Mede tempo de inferencia e coleta probabilidades em validacao.\n",
        "    t0 = time.perf_counter()\n",
        "    p_valid = estimator.predict_proba(X_valid)[:, 1]\n",
        "    latency_valid = (time.perf_counter() - t0) * 1000 / max(1, len(X_valid))\n",
        "\n",
        "    # Repete medicao em teste para comparacao de estabilidade.\n",
        "    t1 = time.perf_counter()\n",
        "    p_test = estimator.predict_proba(X_test)[:, 1]\n",
        "    latency_test = (time.perf_counter() - t1) * 1000 / max(1, len(X_test))\n",
        "\n",
        "    # Threshold padrao para metricas baseadas em classe predita.\n",
        "    yhat_valid = (p_valid >= 0.5).astype(int)\n",
        "    yhat_test = (p_test >= 0.5).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"val_roc_auc\": roc_auc_score(y_valid, p_valid),\n",
        "        \"val_pr_auc\": average_precision_score(y_valid, p_valid),\n",
        "        \"val_brier\": brier_score_loss(y_valid, p_valid),\n",
        "        \"val_f1\": f1_score(y_valid, yhat_valid, zero_division=0),\n",
        "        \"val_precision\": precision_score(y_valid, yhat_valid, zero_division=0),\n",
        "        \"val_recall\": recall_score(y_valid, yhat_valid, zero_division=0),\n",
        "        \"val_latency_ms\": latency_valid,\n",
        "        \"test_roc_auc\": roc_auc_score(y_test, p_test),\n",
        "        \"test_pr_auc\": average_precision_score(y_test, p_test),\n",
        "        \"test_brier\": brier_score_loss(y_test, p_test),\n",
        "        \"test_f1\": f1_score(y_test, yhat_test, zero_division=0),\n",
        "        \"test_precision\": precision_score(y_test, yhat_test, zero_division=0),\n",
        "        \"test_recall\": recall_score(y_test, yhat_test, zero_division=0),\n",
        "        \"test_latency_ms\": latency_test,\n",
        "    }\n",
        "\n",
        "\n",
        "def select_winner(results_df, eps_auc=0.005, eps_pr=0.003, eps_brier=0.002):\n",
        "    # Ordena por metricas principais para iniciar desempate.\n",
        "    ranked = results_df.sort_values([\"val_roc_auc\", \"val_pr_auc\"], ascending=[False, False]).reset_index(drop=True)\n",
        "    a = ranked.iloc[0]\n",
        "    b = ranked.iloc[1]\n",
        "\n",
        "    reasons = []\n",
        "\n",
        "    # Regra 1: ROC-AUC.\n",
        "    if (a[\"val_roc_auc\"] - b[\"val_roc_auc\"]) > eps_auc:\n",
        "        reasons.append(\"ROC-AUC superior sem empate tecnico.\")\n",
        "        return a[\"model\"], reasons\n",
        "\n",
        "    # Regra 2: PR-AUC.\n",
        "    reasons.append(\"Empate tecnico em ROC-AUC; aplicando desempate por PR-AUC.\")\n",
        "    if (a[\"val_pr_auc\"] - b[\"val_pr_auc\"]) > eps_pr:\n",
        "        reasons.append(\"PR-AUC decidiu o vencedor.\")\n",
        "        return a[\"model\"], reasons\n",
        "\n",
        "    # Regra 3: Brier Score (menor e melhor).\n",
        "    reasons.append(\"Empate tecnico em PR-AUC; aplicando desempate por Brier Score.\")\n",
        "    if (b[\"val_brier\"] - a[\"val_brier\"]) > eps_brier:\n",
        "        reasons.append(\"Brier Score decidiu o vencedor (menor e melhor).\")\n",
        "        return a[\"model\"], reasons\n",
        "\n",
        "    # Regra 4: Latencia media de inferencia.\n",
        "    reasons.append(\"Empate tecnico em Brier; aplicando desempate por latencia.\")\n",
        "    if a[\"val_latency_ms\"] <= b[\"val_latency_ms\"]:\n",
        "        reasons.append(\"Latencia de inferencia decidiu o vencedor.\")\n",
        "        return a[\"model\"], reasons\n",
        "\n",
        "    reasons.append(\"Latencia decidiu o vencedor (modelo B).\")\n",
        "    return b[\"model\"], reasons\n",
        "\n",
        "\n",
        "# Avalia somente os melhores da rodada de fine tuning.\n",
        "results = [\n",
        "    evaluate_estimator(\"logit_fine\", fine_logit.best_estimator_, X_valid, y_valid, X_test, y_test),\n",
        "    evaluate_estimator(\"rf_fine\", fine_rf.best_estimator_, X_valid, y_valid, X_test, y_test),\n",
        "]\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(\"val_roc_auc\", ascending=False).reset_index(drop=True)\n",
        "winner_name, winner_reasons = select_winner(results_df)\n",
        "\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7426b4b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabela com realce visual para facilitar leitura de decisao no pitch.\n",
        "display(\n",
        "    results_df.style\n",
        "    .format({\n",
        "        \"val_roc_auc\": \"{:.4f}\",\n",
        "        \"val_pr_auc\": \"{:.4f}\",\n",
        "        \"val_brier\": \"{:.4f}\",\n",
        "        \"val_f1\": \"{:.4f}\",\n",
        "        \"val_precision\": \"{:.4f}\",\n",
        "        \"val_recall\": \"{:.4f}\",\n",
        "        \"val_latency_ms\": \"{:.4f}\",\n",
        "        \"test_roc_auc\": \"{:.4f}\",\n",
        "        \"test_pr_auc\": \"{:.4f}\",\n",
        "        \"test_brier\": \"{:.4f}\",\n",
        "        \"test_f1\": \"{:.4f}\",\n",
        "        \"test_precision\": \"{:.4f}\",\n",
        "        \"test_recall\": \"{:.4f}\",\n",
        "        \"test_latency_ms\": \"{:.4f}\",\n",
        "    })\n",
        "    # Verde: quanto maior melhor.\n",
        "    .background_gradient(subset=[\"val_roc_auc\", \"val_pr_auc\", \"test_roc_auc\", \"test_pr_auc\"], cmap=\"Greens\")\n",
        "    # Vermelho invertido: quanto menor melhor (brier e latencia).\n",
        "    .background_gradient(subset=[\"val_brier\", \"test_brier\", \"val_latency_ms\", \"test_latency_ms\"], cmap=\"OrRd_r\")\n",
        ")\n",
        "\n",
        "print(f\"[WINNER] Modelo vencedor: {winner_name}\")\n",
        "for r in winner_reasons:\n",
        "    print(f\"  - {r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d07dd9b",
      "metadata": {},
      "source": [
        "## &#128190; Persistencia dos Artefatos\n",
        "\n",
        "Salva campeao, vice e relatorio de selecao para integracao com API de scoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "02f037da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Artefatos salvos com sucesso:\n",
            " - data\\ml\\artifacts\\lead_scoring_best_model.joblib\n",
            " - data\\ml\\artifacts\\lead_scoring_runner_up_model.joblib\n",
            " - data\\ml\\artifacts\\model_selection_report.json\n"
          ]
        }
      ],
      "source": [
        "# Mapeia nomes para os estimadores finais treinados.\n",
        "model_map = {\n",
        "    \"logit_fine\": fine_logit.best_estimator_,\n",
        "    \"rf_fine\": fine_rf.best_estimator_,\n",
        "}\n",
        "\n",
        "# Define campeao e vice para uso operacional (champion/challenger).\n",
        "best_model = model_map[winner_name]\n",
        "runner_up_name = [m for m in model_map.keys() if m != winner_name][0]\n",
        "runner_up_model = model_map[runner_up_name]\n",
        "\n",
        "# Persistencia de modelos em joblib para inferencia no scoring_service.\n",
        "joblib.dump(best_model, ARTIFACT_DIR / \"lead_scoring_best_model.joblib\")\n",
        "joblib.dump(runner_up_model, ARTIFACT_DIR / \"lead_scoring_runner_up_model.joblib\")\n",
        "\n",
        "# Relatorio para auditoria e reproducao da decisao de modelo.\n",
        "report = {\n",
        "    \"winner\": winner_name,\n",
        "    \"runner_up\": runner_up_name,\n",
        "    \"selection_reasons\": winner_reasons,\n",
        "    \"metrics\": results_df.to_dict(orient=\"records\"),\n",
        "    \"random_state\": RANDOM_STATE,\n",
        "    \"target_col\": TARGET_COL,\n",
        "}\n",
        "\n",
        "with open(ARTIFACT_DIR / \"model_selection_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(report, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"[OK] Artefatos salvos com sucesso:\")\n",
        "print(f\" - {ARTIFACT_DIR / 'lead_scoring_best_model.joblib'}\")\n",
        "print(f\" - {ARTIFACT_DIR / 'lead_scoring_runner_up_model.joblib'}\")\n",
        "print(f\" - {ARTIFACT_DIR / 'model_selection_report.json'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b90c3af3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumo dos artefatos\n",
            "total 792K\n",
            "-rwxrwxrwx 1 luizandre luizandre 5.9K Feb 15 16:55 lead_scoring_best_model.joblib\n",
            "-rwxrwxrwx 1 luizandre luizandre 779K Feb 15 16:55 lead_scoring_runner_up_model.joblib\n",
            "-rwxrwxrwx 1 luizandre luizandre 1.3K Feb 15 16:55 model_selection_report.json\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "echo \"Resumo dos artefatos\"\n",
        "ls -lh data/ml/artifacts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "361ca0fc",
      "metadata": {},
      "source": [
        "## &#128268; Proximo Passo de Integracao\n",
        "\n",
        "1. Copiar `lead_scoring_best_model.joblib` para o servico de scoring\n",
        "2. Atualizar o endpoint `/score` para consumir o modelo campeao\n",
        "3. Manter o `runner_up_model` como fallback tecnico\n",
        "4. Versionar o JSON de selecao para auditoria no pitch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683b8671",
      "metadata": {},
      "source": [
        "## &#9203; Execução CLI (sem notebook)\n",
        "\n",
        "Se preferir rodar fora do Jupyter, use o script:\n",
        "\n",
        "```bash\n",
        "python tools/ml/train_lead_scoring.py --input-csv data/ml/lead_scoring_dataset.csv --output-dir data/ml/artifacts\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c61b0a7c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executando: c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\.venv\\Scripts\\python.exe c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\tools\\ml\\train_lead_scoring.py --input-csv c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\data\\ml\\lead_scoring_dataset.csv --output-dir c:\\Users\\USER\\Documents\\Repositorios\\growth_equestre_hackathon_2026_backup\\data\\ml\\artifacts\n",
            "Treino via CLI concluido com sucesso.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Ajusta raiz do repo automaticamente\n",
        "cwd = Path.cwd()\n",
        "repo_root = cwd\n",
        "for p in [cwd, *cwd.parents]:\n",
        "    if (p / \"tools\" / \"ml\" / \"train_lead_scoring.py\").exists():\n",
        "        repo_root = p\n",
        "        break\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    str(repo_root / \"tools\" / \"ml\" / \"train_lead_scoring.py\"),\n",
        "    \"--input-csv\",\n",
        "    str(repo_root / \"data\" / \"ml\" / \"lead_scoring_dataset.csv\"),\n",
        "    \"--output-dir\",\n",
        "    str(repo_root / \"data\" / \"ml\" / \"artifacts\"),\n",
        "]\n",
        "\n",
        "print(\"Executando:\", \" \".join(cmd))\n",
        "subprocess.check_call(cmd, cwd=repo_root)\n",
        "print(\"Treino via CLI concluido com sucesso.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
